{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Transfer learning (20 marks)\n",
    "\n",
    "<b>When we learn to solve a new problem, we often leverage on knowledge that we have learned on related tasks. \n",
    "For example, when we learn how to play chess after learning how to play Chinese chess, we can often quickly learn new tactics for chess by relating to tactics that we have learned for Chinese chess.</b>\n",
    "    \n",
    "<b>Exploiting previously acquired knowledge on related tasks to learn how to solve new problems is known as transfer learning, and this idea has been applied to build machine learning systems too.\n",
    "</b>\n",
    "\n",
    "<b>In this question, we will exploit a model learned on a noisy version of MNIST to learn a model on MNIST.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(a) (0 marks) \n",
    "The code below loads a model trained on a noisy version of MNIST, with all pixel values normalized to the range [0,1]. Some of the noisy MNIST images are shown on the left figure below, together with some of the original MNIST images shown on the right figure below for comparsion.</b>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src='supplements/noisy_mnist.png' width=450></td>\n",
    "        <td><img src='supplements/clean_mnist.png' width=450></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<b>The model is actually a feature network that converts an input image into a feature vector.\n",
    "Read and run the code to understand how it works.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T06:59:22.966132Z",
     "start_time": "2021-04-01T06:59:21.841635Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0391, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0777, 0.0000, 0.0156, 0.0000, 0.3461, 0.0000, 0.0000,\n",
       "         0.0000, 0.3623, 0.0000, 0.2485, 0.0000, 0.0379, 0.0000, 0.0000, 0.0805,\n",
       "         0.0000, 0.4608, 0.0000, 0.0000, 0.0000, 0.0801, 0.0000, 0.4491, 0.0000,\n",
       "         0.4415, 0.0000, 0.0000, 0.0000, 0.0000, 0.2143, 0.0000, 0.0000, 0.1327,\n",
       "         0.0370, 0.2791, 0.2252, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4022,\n",
       "         0.0000, 0.0493, 0.2590, 0.3733, 0.0000, 0.0652, 0.0000, 0.3416, 0.0000,\n",
       "         0.0000, 0.0000, 0.2686, 0.1027, 0.0000, 0.0000, 0.0000, 0.0000, 0.3687,\n",
       "         0.0000, 0.1193, 0.1195, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1117,\n",
       "         0.1916, 0.0717, 0.0660],\n",
       "        [0.0000, 0.0000, 0.2519, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0085, 0.0000, 0.0000, 0.0000, 0.3275, 0.0935, 0.0000,\n",
       "         0.0000, 0.2554, 0.0000, 0.0000, 0.0000, 0.1352, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2656, 0.0000, 0.0000, 0.1380,\n",
       "         0.0000, 0.1464, 0.2685, 0.0000, 0.0049, 0.0000, 0.0000, 0.0000, 0.2208,\n",
       "         0.0000, 0.0793, 0.1792, 0.3970, 0.0000, 0.1683, 0.0000, 0.2408, 0.0000,\n",
       "         0.0000, 0.0000, 0.0664, 0.2645, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1580, 0.2518, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0301,\n",
       "         0.2544, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1202, 0.0000, 0.0332, 0.0000, 0.4018, 0.0175, 0.0000,\n",
       "         0.0000, 0.3675, 0.0000, 0.1525, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.2391, 0.0000, 0.0000, 0.0000, 0.0228, 0.0000, 0.3851, 0.0000,\n",
       "         0.2023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0735,\n",
       "         0.0000, 0.2057, 0.2342, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824,\n",
       "         0.0000, 0.1025, 0.3659, 0.4153, 0.0000, 0.0946, 0.0158, 0.3963, 0.0073,\n",
       "         0.0000, 0.0209, 0.1880, 0.0993, 0.0000, 0.0000, 0.0000, 0.0000, 0.2767,\n",
       "         0.0000, 0.0000, 0.0355, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0908,\n",
       "         0.2507, 0.0585, 0.1289]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1)\n",
    "# load the feature network\n",
    "feature_net = torch.load('supplements/fnet.pt')\n",
    "# create 3 random images of size 1x28x28\n",
    "images = torch.rand(3, 1, 28, 28)\n",
    "# compute the features for the 3 random images\n",
    "feature_net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(b) (5 marks)\n",
    "Load the MNIST dataset and convert the images into feature vectors using the provided feature network</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**. [Write your solution here. Add cells as needed.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T06:59:25.052202Z",
     "start_time": "2021-04-01T06:59:22.968131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the raw MINST training set is torch.Size([60000, 1, 28, 28])\n",
      "The shape of the raw MINST test set is torch.Size([10000, 1, 28, 28])\n",
      "The shape of the transformed MINST training set is torch.Size([60000, 84])\n",
      "The shape of the transformed MINST test set is torch.Size([10000, 84])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "# Download data\n",
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root=\"../data\", train=True,\n",
    "                                         transform=trans,\n",
    "                                         download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root=\"../data\", train=False,\n",
    "                                        transform=trans,\n",
    "                                        download=True)\n",
    "\n",
    "x_train, y_train = mnist_train.data.view(-1, 1, 28, 28), mnist_train.targets\n",
    "x_test, y_test = mnist_test.data.view(-1, 1, 28, 28), mnist_test.targets\n",
    "\n",
    "# Transform\n",
    "transformed_tr_x = feature_net(x_train.float())\n",
    "transformed_test_x = feature_net(x_test.float())\n",
    "\n",
    "print('The shape of the raw MINST training set is {}'.format(x_train.shape))\n",
    "print('The shape of the raw MINST test set is {}'.format(x_test.shape))\n",
    "print('The shape of the transformed MINST training set is {}'.format(transformed_tr_x.shape))\n",
    "print('The shape of the transformed MINST test set is {}'.format(transformed_test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(c) (10 marks)\n",
    "Pick a simple classifier of your choice, train it on MNIST using the pixel values as features, and also train it using the features extracted in (b).\n",
    "Compare and comment on the performances of the two models.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**. [Write your solution here. Add cells as needed.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T06:59:25.207133Z",
     "start_time": "2021-04-01T06:59:25.055200Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T06:59:25.222125Z",
     "start_time": "2021-04-01T06:59:25.209132Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "batch_size = 200\n",
    "# 转换为 mini-batch\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True)\n",
    "test_iter = data.DataLoader(mnist_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:05:28.038334Z",
     "start_time": "2021-04-01T07:05:28.001351Z"
    }
   },
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "def accuracy(y, y_hat):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(sum(cmp.type(y.dtype)))\n",
    "\n",
    "\n",
    "def train_epoch(net, train_iter, loss, updater, ctx):\n",
    "    \"\"\"The training loop defined in Chapter 3.\"\"\"\n",
    "    # Set the model to training mode\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.train()\n",
    "    # Sum of training loss, sum of training accuracy, no. of examples\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        X = X.to(ctx)  # GPU\n",
    "        y = y.to(ctx)\n",
    "        # Compute gradients and update parameters\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        # Using PyTorch in-built optimizer & loss criterion\n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "        acc = accuracy(y, y_hat)\n",
    "        metric.add(float(l) * len(y), acc, len(y))\n",
    "    # Return training loss and training accuracy\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "\n",
    "def evaluate_accuracy(net, data_iter, ctx):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "    metric = Accumulator(2)  # No. of correct predictions, no. of predictions\n",
    "    for X, y in data_iter:\n",
    "        X = X.to(ctx)  # GPU\n",
    "        y = y.to(ctx)\n",
    "        y_hat = net(X)\n",
    "        acc = accuracy(y, y_hat)\n",
    "        metric.add(acc, len(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "def train_op(net, train_iter, test_iter, loss, num_epochs, updater, ctx):\n",
    "    \"\"\"Train a model\"\"\"\n",
    "    met = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            net, train_iter, loss, updater, ctx)\n",
    "        test_acc = evaluate_accuracy(net, test_iter, ctx)\n",
    "        met.append([train_loss, train_acc, test_acc])\n",
    "        print(epoch, met[-1])\n",
    "    return met\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes, ctx):\n",
    "        super().__init__()\n",
    "        self.output = nn.Sequential(nn.Linear(84, 20), nn.ReLU(),\n",
    "                                    nn.Linear(20, num_classes))\n",
    "        self.feature_net = torch.load('supplements/fnet.pt').to(ctx)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # feature_net 的网络仅仅作为特征提取器，不加入训练\n",
    "        x = self.feature_net(x).detach()\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "def tune_net(ctx):\n",
    "    # 添加 feature_net 的网络\n",
    "    fine_net = Net(10, ctx)\n",
    "    # 初始化 output\n",
    "    fine_net.output.apply(init_weights)\n",
    "    return fine_net.to(ctx)\n",
    "\n",
    "\n",
    "def simple_net(ctx):\n",
    "    # 自定义简单网络\n",
    "    net = nn.Sequential(nn.Flatten(), nn.Linear(784, 100), nn.ReLU(),\n",
    "                        nn.Linear(100, 10))\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(ctx)\n",
    "    return net\n",
    "\n",
    "\n",
    "def train_model(net, train_iter, test_iter, num_epochs, lr, ctx):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    updater = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    return train_op(net, train_iter, test_iter, loss, num_epochs, updater, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:01:22.881223Z",
     "start_time": "2021-04-01T06:59:27.127276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [2.283632703622182, 0.21338333333333334, 0.3923]\n",
      "1 [2.08078292409579, 0.4797166666666667, 0.6117]\n",
      "2 [1.4623488477865856, 0.6755666666666666, 0.7403]\n",
      "3 [0.9585869296391805, 0.7729666666666667, 0.8107]\n",
      "4 [0.7274836311737697, 0.8195, 0.8375]\n",
      "5 [0.6075268289446831, 0.8436833333333333, 0.8583]\n",
      "6 [0.5353246752421061, 0.8612, 0.8707]\n",
      "7 [0.4871647572517395, 0.8710166666666667, 0.8816]\n",
      "8 [0.45304203937451043, 0.87815, 0.8857]\n",
      "9 [0.4275187399983406, 0.8839833333333333, 0.8914]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "ctx = device\n",
    "# 简单网络\n",
    "net = simple_net(ctx)\n",
    "## 打印 train_loss, train_acc, test_acc\n",
    "net_metric = train_model(net, train_iter, test_iter, num_epochs, lr, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:07:29.513128Z",
     "start_time": "2021-04-01T07:05:32.190482Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [2.3061318389574685, 0.0993, 0.1032]\n",
      "1 [2.296882341702779, 0.0993, 0.1032]\n",
      "2 [2.2671200823783875, 0.26021666666666665, 0.4782]\n",
      "3 [2.1326989591121674, 0.46536666666666665, 0.4822]\n",
      "4 [1.751803803841273, 0.51865, 0.6193]\n",
      "5 [1.378192971944809, 0.7703166666666666, 0.7928]\n",
      "6 [1.0740847325325011, 0.8106666666666666, 0.8134]\n",
      "7 [0.7949317284425099, 0.8594333333333334, 0.8783]\n",
      "8 [0.6063695382078489, 0.89355, 0.8835]\n",
      "9 [0.48111656844615935, 0.8939666666666667, 0.883]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "ctx = device\n",
    "# 有 feature_net 的网络\n",
    "fine_net = tune_net(ctx)\n",
    "## 打印 train_loss, train_acc, test_acc\n",
    "fine_net_metric = train_model(fine_net, train_iter, test_iter, num_epochs, lr, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(d) (5 marks) We investigate how the features learned on noisy MNIST transfer to another variant of MNIST where each image has a small random 3x3 patches cut out. Read and run the code below to understand how it works. Repeat (c) on this damaged MNIST dataset. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:07:51.319397Z",
     "start_time": "2021-04-01T07:07:47.681021Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def randcut(x, patch_size=(3,3)):\n",
    "    x = copy.deepcopy(x)\n",
    "    h, w = patch_size\n",
    "    H, W = x.shape[-2:]\n",
    "    for i in range(len(x)):\n",
    "        a = np.random.choice(H-h)\n",
    "        b = np.random.choice(W-w)\n",
    "        x[i, ..., a:a+h, b:b+w] = 255\n",
    "    return x\n",
    "\n",
    "# randomly cut 3x3 patches out from MNIST images\n",
    "np.random.seed(3)\n",
    "x_tr_cut = randcut(x_train)\n",
    "x_ts_cut = randcut(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:07:51.600272Z",
     "start_time": "2021-04-01T07:07:51.322395Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the first modified training image\n",
    "plt.imshow(x_tr_cut[0, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**. [Write your solution here. Add cells as needed.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:07:56.190269Z",
     "start_time": "2021-04-01T07:07:56.089314Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "batch_size = 200\n",
    "# 转换为 mini-batch\n",
    "train_iter2 = data.DataLoader(data.TensorDataset(x_tr_cut.float(), y_train), batch_size, shuffle=True)\n",
    "test_iter2 = data.DataLoader(data.TensorDataset(x_ts_cut.float(), y_test), batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:10:52.532884Z",
     "start_time": "2021-04-01T07:10:19.940919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.2669313360502322, 0.9344833333333333, 0.9619]\n",
      "1 [0.141679997574538, 0.96555, 0.9635]\n",
      "2 [0.13322195671498777, 0.9673333333333334, 0.9632]\n",
      "3 [0.12834526741256316, 0.9686, 0.962]\n",
      "4 [0.12575038690119983, 0.96875, 0.965]\n",
      "5 [0.12316020347177982, 0.96935, 0.9649]\n",
      "6 [0.12110256279508273, 0.9696, 0.9647]\n",
      "7 [0.11934442209079861, 0.9699333333333333, 0.9664]\n",
      "8 [0.11808202559749285, 0.9700166666666666, 0.963]\n",
      "9 [0.11701808537046114, 0.9704, 0.9656]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "ctx = device\n",
    "# 有 feature_net 的网络\n",
    "fine_net = tune_net(ctx)\n",
    "## 打印 train_loss, train_acc, test_acc\n",
    "fine_net_metric = train_model(fine_net, train_iter2, test_iter2, num_epochs, lr, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T07:10:13.393841Z",
     "start_time": "2021-04-01T07:09:44.213862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [2.8120475745201112, 0.18361666666666668, 0.2005]\n",
      "1 [1.9773447461922964, 0.24755, 0.2438]\n",
      "2 [1.9647116732597352, 0.243, 0.2974]\n",
      "3 [1.8964827688535055, 0.26975, 0.301]\n",
      "4 [1.853070008357366, 0.28478333333333333, 0.2098]\n",
      "5 [2.0184892431894936, 0.2125, 0.2152]\n",
      "6 [2.004334104061127, 0.21796666666666667, 0.2118]\n",
      "7 [2.0061639066537222, 0.21161666666666668, 0.2127]\n",
      "8 [1.997455381155014, 0.21921666666666667, 0.2138]\n",
      "9 [2.0037748448053994, 0.21351666666666666, 0.2158]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "ctx = device\n",
    "# 简单网络\n",
    "net = simple_net(ctx)\n",
    "## 打印 train_loss, train_acc, test_acc\n",
    "net_metric = train_model(net, train_iter2, test_iter2, num_epochs, lr, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
